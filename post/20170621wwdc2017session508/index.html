
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  
    <title>【iOS】iPhone摄影中的深度捕捉(WWDC2017-Session 507) | YoferZhang 的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Yofer Zhang">
    

    
    <meta name="description" content="版权声明：本文为博主原创，如需转载请注明出处。

视频地址,只能用safari观看
前言507是深度媒体相关的概念层面的内容。主要为下面4个部分：

Depth and disparity on iPhone 7 Plus
Streaming depth data from the camera
Capturing photos with depth data
Dual photo captur">
<meta property="og:type" content="article">
<meta property="og:title" content="【iOS】iPhone摄影中的深度捕捉(WWDC2017-Session 507)">
<meta property="og:url" content="http://yoferzhang.com/post/20170621wwdc2017session508/index.html">
<meta property="og:site_name" content="YoferZhang 的博客">
<meta property="og:description" content="版权声明：本文为博主原创，如需转载请注明出处。

视频地址,只能用safari观看
前言507是深度媒体相关的概念层面的内容。主要为下面4个部分：

Depth and disparity on iPhone 7 Plus
Streaming depth data from the camera
Capturing photos with depth data
Dual photo captur">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsk5mhrkoj21kw0vmgro.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0rc12tej21kw0w7h0b.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgs0souhprj21kw0whjzj.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0t7tvejj21kw0w24b1.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0udhn92j21kw0vtk0e.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0usl424j21kw0vu76f.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs0veakdxj21kw0vqthw.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs0vyqlp3j21kw0vtqbu.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0wj0wrjj21kw0vvaip.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0x03s6yj21kw0vpmzw.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0xfj8fsj21kw0vr40o.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0y1xhhtj21kw0vrdi4.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0yhl1a0j21kw0vn7cf.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0yvnzylj21kw0vv465.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0zbhu5xj21kw0vpac2.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgs0zsmc7qj21kw0vvacq.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs108ohslj21kw0vk41a.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs117ecxbj21kw0ve0w7.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs11wgeftj21kw0vtq6f.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs12b2e4lj21kw0vq0v1.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs12rivh1j21kw0vv0w3.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsk6uz915j21kw0vladn.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs13xhh7yj21kw0vfgow.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs17ml93mj222e15gtco.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs17ml93mj222e15gtco.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj1gk7i2j21kw0vm41a.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj1ys4duj21kw0vmgno.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj2f0f3nj21kw0viwhm.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsj2uci13j21kw0vlgn9.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj3e7ymsj21kw0c2gmv.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj3retmxj21kw0dm0tm.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj45svipj21kw0vb0w9.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj4kyda4j21kw0vldl7.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj73ubzej21kw0n043r.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsj7z7mzqj21kw0j2773.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsj8emigvj21kw0ul444.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsj8s3gxgj21kw0vjdm7.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj96x8qej21kw0qnado.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj9m3a0pj21kw0r2got.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj9zc3glj21kw0q2tbq.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjacfo37j21kw0s4wi7.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjaphyivj21fm0m2n65.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjb6bur5j209s0c2n1n.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjbjoem0j20yi1pckb1.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjby5psej21e20ec0u5.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjcbgjusj21kw0t4q6u.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjcpmo86j21kw0qwtfa.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjd6bbfmj21kw0men2h.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjdkh5f8j21jw0x2409.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjdy15ayj21ei0wugs8.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjebq38zj21kw0y17a0.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjeoutp6j21kw0rl79d.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjf34n5zj21kw0hfact.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjifd9fyj21kw0dhjv1.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjita42uj21kw0kgjv6.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjj6uqnyj21kw0j9adw.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjjnx0fej21h00nm4jf.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjk05091j21kw0h643o.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjkecu5zj21kw0eu0v8.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjkscp53j21kw0nhq95.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjl4do87j21kw0b5mzb.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjlgvpy2j21ic0cyac0.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjltcn79j21kw0midix.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjm6qrydj21kw0olmzw.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjmjskgjj21kw0nv41b.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjmyjqafj21kw0o4q7g.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjnb85n2j21kw0oin1a.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjnqsllkj21kw0s87c6.jpg">
<meta property="og:updated_time" content="2018-06-05T13:03:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="【iOS】iPhone摄影中的深度捕捉(WWDC2017-Session 507)">
<meta name="twitter:description" content="版权声明：本文为博主原创，如需转载请注明出处。

视频地址,只能用safari观看
前言507是深度媒体相关的概念层面的内容。主要为下面4个部分：

Depth and disparity on iPhone 7 Plus
Streaming depth data from the camera
Capturing photos with depth data
Dual photo captur">
<meta name="twitter:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsk5mhrkoj21kw0vmgro.jpg">
<meta name="twitter:creator" content="@LuciferZhangyq">
<link rel="publisher" href="110295955443575724222">

    
    <link rel="alternative" href="/atom.xml" title="YoferZhang 的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/faviconr.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.jpg" alt="YoferZhang 的博客" title="YoferZhang 的博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="YoferZhang 的博客">YoferZhang 的博客</a></h1>
				<h2 class="blog-motto">数学出身，功底扎实，热爱编程，虽然编程起步晚，但是冲劲十足。</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/index/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:yoferzhang.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/post/20170621wwdc2017session508/" title="【iOS】iPhone摄影中的深度捕捉(WWDC2017-Session 507)" itemprop="url">【iOS】iPhone摄影中的深度捕捉(WWDC2017-Session 507)</a>
  </h1>
  <p class="article-author">By
       
		<a href="https://plus.google.com/110295955443575724222?rel=author" title="Yofer Zhang" target="_blank" itemprop="author">Yofer Zhang</a>
		
  <p class="article-time">
    <time datetime="2017-06-21T12:21:48.000Z" itemprop="datePublished"> 发表于 2017-06-21</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Depth-and-disparity-on-iPhone-7-Plus"><span class="toc-number">2.</span> <span class="toc-text">Depth and disparity on iPhone 7 Plus</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Dual-Camera-Zoom-双摄变焦"><span class="toc-number">2.1.</span> <span class="toc-text">Dual Camera Zoom 双摄变焦</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Portrait-Mode"><span class="toc-number">2.2.</span> <span class="toc-text">Portrait Mode</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Deep-Learning"><span class="toc-number">3.</span> <span class="toc-text">Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Map"><span class="toc-number">3.1.</span> <span class="toc-text">Depth Map</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Disparity"><span class="toc-number">3.2.</span> <span class="toc-text">Disparity</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#baseline基线"><span class="toc-number">3.2.1.</span> <span class="toc-text">baseline基线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Z"><span class="toc-number">3.2.2.</span> <span class="toc-text">Z</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Removing-Despair-from-Disparity"><span class="toc-number">3.2.3.</span> <span class="toc-text">Removing Despair from Disparity</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Disparity-vs-Depth"><span class="toc-number">3.3.</span> <span class="toc-text">Disparity vs. Depth</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#New-Term-Depth-Data"><span class="toc-number">4.</span> <span class="toc-text">New Term: Depth Data</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introducing-AVDepthData"><span class="toc-number">4.1.</span> <span class="toc-text">Introducing AVDepthData</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Holes"><span class="toc-number">4.1.1.</span> <span class="toc-text">Holes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Calibration-Errors-校准错误"><span class="toc-number">4.1.2.</span> <span class="toc-text">Calibration Errors 校准错误</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Depth-Data-Accuracy"><span class="toc-number">4.1.3.</span> <span class="toc-text">Depth Data Accuracy</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Streaming-Depth-Data"><span class="toc-number">5.</span> <span class="toc-text">Streaming Depth Data</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AVCamPhotoFilter"><span class="toc-number">5.1.</span> <span class="toc-text">AVCamPhotoFilter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introducing-AVCaptureDepthDataOutput"><span class="toc-number">5.2.</span> <span class="toc-text">Introducing AVCaptureDepthDataOutput</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Supported-Depth-Resolutions-for-Streaming"><span class="toc-number">5.3.</span> <span class="toc-text">Supported Depth Resolutions for Streaming</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Frame-Rate-Examples"><span class="toc-number">5.4.</span> <span class="toc-text">Depth Frame Rate Examples</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非同步数据输出"><span class="toc-number">5.5.</span> <span class="toc-text">非同步数据输出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Synchronized-Data-Output"><span class="toc-number">5.6.</span> <span class="toc-text">Synchronized Data Output</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Streaming-Camera-Intrinsics"><span class="toc-number">5.7.</span> <span class="toc-text">Streaming Camera Intrinsics</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Capturing-Photos-with-Depth"><span class="toc-number">6.</span> <span class="toc-text">Capturing Photos with Depth</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Photos-with-Depth"><span class="toc-number">6.1.</span> <span class="toc-text">Photos with Depth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Capturing-Photos-with-Depth-1"><span class="toc-number">6.2.</span> <span class="toc-text">Capturing Photos with Depth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requesting-Depth-with-Photos"><span class="toc-number">6.3.</span> <span class="toc-text">Requesting Depth with Photos</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#High-Res-Photo-Depth-Maps"><span class="toc-number">6.4.</span> <span class="toc-text">High Res Photo Depth Maps</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rectilinear-vs-Lens-Distorted-Images"><span class="toc-number">6.5.</span> <span class="toc-text">Rectilinear vs. Lens Distorted Images</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Map-Distortions"><span class="toc-number">6.6.</span> <span class="toc-text">Depth Map Distortions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-in-Image-Files"><span class="toc-number">6.7.</span> <span class="toc-text">Depth in Image Files</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dual-Photo-Capture"><span class="toc-number">7.</span> <span class="toc-text">Dual Photo Capture</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Requesting-Dual-Photo-Delivery"><span class="toc-number">7.1.</span> <span class="toc-text">Requesting Dual Photo Delivery</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dual-Photo-Capture-1"><span class="toc-number">7.2.</span> <span class="toc-text">Dual Photo Capture</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dual-Photo-Capture-Zoom"><span class="toc-number">7.3.</span> <span class="toc-text">Dual Photo Capture + Zoom</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introducing-AVCameraCalibrationData"><span class="toc-number">7.4.</span> <span class="toc-text">Introducing AVCameraCalibrationData</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#intrinsicMatrix"><span class="toc-number">7.4.1.</span> <span class="toc-text">intrinsicMatrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#extrinsicMatrix"><span class="toc-number">7.4.2.</span> <span class="toc-text">extrinsicMatrix</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Summary"><span class="toc-number">8.</span> <span class="toc-text">Summary</span></a></li></ol>
		
		</div>
		
		<blockquote>
<p>版权声明：本文为博主原创，如需转载请注明出处。</p>
</blockquote>
<p><a href="https://developer.apple.com/videos/play/wwdc2017/507/" target="_blank" rel="external">视频地址,只能用safari观看</a></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>507是深度媒体相关的概念层面的内容。主要为下面4个部分：</p>
<ul>
<li>Depth and disparity on iPhone 7 Plus</li>
<li>Streaming depth data from the camera</li>
<li>Capturing photos with depth data</li>
<li>Dual photo capture</li>
</ul>
<h1 id="Depth-and-disparity-on-iPhone-7-Plus"><a href="#Depth-and-disparity-on-iPhone-7-Plus" class="headerlink" title="Depth and disparity on iPhone 7 Plus"></a>Depth and disparity on iPhone 7 Plus</h1><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsk5mhrkoj21kw0vmgro.jpg" alt=""></p>
<p>7 Plus 有两个摄像头，28毫米的广角摄像头，56毫米的长焦镜头。它们都是1200万像素，分享同样的配置项、格式。可以单独使用它们，也可以用一个虚拟的第三方摄像头来共同使用它们，使它们配合。它以同步的方式运行，相同的帧速率，并且一起运行它们可以实现两个选框功能。</p>
<h2 id="Dual-Camera-Zoom-双摄变焦"><a href="#Dual-Camera-Zoom-双摄变焦" class="headerlink" title="Dual Camera Zoom 双摄变焦"></a>Dual Camera Zoom 双摄变焦</h2><ul>
<li>Switches between wide and tele automatically </li>
<li>Matches exposure, focus, and frame rate </li>
<li><p>Compensates for parallax shift to smooth the transition</p>
</li>
<li><p>在缩放时，会自动切换广角与长焦；</p>
</li>
<li>适配曝光、对焦和帧速率；</li>
<li>对视差偏移进行补偿，使其在广角和长焦之间来回切换时平滑过渡。</li>
</ul>
<h2 id="Portrait-Mode"><a href="#Portrait-Mode" class="headerlink" title="Portrait Mode"></a>Portrait Mode</h2><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0rc12tej21kw0w7h0b.jpg" alt=""></p>
<p>人像模式锁定在长焦摄像头，但是会同时使用广角和长焦来生成一副浅景深效果的图像。聚焦的<strong>前景</strong>清晰，<strong>背景</strong>则会逐渐模糊。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgs0souhprj21kw0whjzj.jpg" alt=""></p>
<p>iOS11 上改进了对焦区域的渲染。更准确的展现了一个自由度高的快速镜头，例如上图中清晰明亮的花束圈。还改进了前景和背景边缘的渲染。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0t7tvejj21kw0w24b1.jpg" alt=""></p>
<p>为了生成这样效果的图片，就要有能力区分前景和背景，也就是需要<strong>depth</strong>。在iOS10，depth信息还只是包含在苹果自己相机的人像模式中。iOS11，苹果正在向第三方应用开放depth map。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0udhn92j21kw0vtk0e.jpg" alt=""></p>
<p>上面这幅图中内嵌了下面这样一个灰度可视化的深度图：</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0usl424j21kw0vu76f.jpg" alt=""></p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs0veakdxj21kw0vqthw.jpg" alt=""></p>
<p>深度信息有了对图像编辑更多的可能性，例如上图对前景和背景应用不同的滤光器；将黑白滤光器应用到背景，Fade Filter应用到前景。</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs0vyqlp3j21kw0vtqbu.jpg" alt=""></p>
<p>也可以像上图，将前景的范围缩小到手和花。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0wj0wrjj21kw0vvaip.jpg" alt=""></p>
<p>还可以对前景和背景应用不同的曝光</p>
<h1 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h1><h2 id="Depth-Map"><a href="#Depth-Map" class="headerlink" title="Depth Map"></a>Depth Map</h2><p>首先定义depth map。真实世界中depth 意思是你和观察物体之间的距离。深度图是将三维场景转化为二维表示，并将深度设置为恒定距离。</p>
<p>下面对针孔相机做一点研究：</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0x03s6yj21kw0vpmzw.jpg" alt=""></p>
<p>针孔相机是一个没有镜头的简单的防光盒，观察物体通过一个孔映射到传感器上。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0xfj8fsj21kw0vr40o.jpg" alt=""></p>
<p>光线通过的孔被称为焦点，聚焦到成像平面的距离就是焦距，物体在成像平面上的缩放程度就取决于焦距。较短的焦距意味着更宽的视野；而更长的焦距，较长的盒子意味着较窄的视野。</p>
<p>简单来说，深度图是将3D深度转换为2D，单通道图像，其中每个像素值是不同的深度，如五米，四米，三米。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0y1xhhtj21kw0vrdi4.jpg" alt=""></p>
<p>为了真正测量深度，需要一个专用的摄像头，比如飞行时间相机。例如，一个系统，它从物体反射光信号，然后测量返回到传感器所需的时间。</p>
<p>iPhone 7双摄像头不是飞行时间相机。相反，它是一个基于<strong>Disparity</strong>的系统。</p>
<h2 id="Disparity"><a href="#Disparity" class="headerlink" title="Disparity"></a>Disparity</h2><p>Disparity 是从两个不同的摄像机（如眼球）观测到的物体的偏移量的量度。Disparity 是视差的另一个名称。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0yhl1a0j21kw0vn7cf.jpg" alt=""></p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs0yvnzylj21kw0vv465.jpg" alt=""></p>
<p>你可以通过稳定头部并将目光固定在靠近的位置上观察此效果，然后不移动您的头部，闭上一只眼睛，然后闭上另一只眼睛。而且你可以看到彩色的铅笔看起来比后面的标记更多，因为它们更接近。这就是 Disparity效果，或者说视差效果。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs0zbhu5xj21kw0vpac2.jpg" alt=""></p>
<p>现在我已经拍摄了两台被认为是立体纠正相机的鸟瞰图。意思是说，它们彼此平行，它们指向同一个方向，而且焦距是相同的，这个很重要。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgs0zsmc7qj21kw0vvacq.jpg" alt=""></p>
<p>每个相机将具有测量的光学中心或主要点，并且如果从针孔到图像平面绘制垂直线，则光学中心是其与图像平面相交的点。</p>
<h3 id="baseline基线"><a href="#baseline基线" class="headerlink" title="baseline基线"></a>baseline基线</h3><p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs108ohslj21kw0vk41a.jpg" alt=""></p>
<p>基线是指立体纠正系统中透镜的两个光学中心之间的距离。 下面是它的工作原理：</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs117ecxbj21kw0ve0w7.jpg" alt=""></p>
<p>来自被观察物体的光穿过光学中心，或者说穿过两个照相机的图像平面上的不同点的孔径和平台。</p>
<h3 id="Z"><a href="#Z" class="headerlink" title="Z"></a>Z</h3><p>Z是深度或者真实世界深度的规范术语</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs11wgeftj21kw0vtq6f.jpg" alt=""></p>
<p>现在看看当观察点越远，图像平面上的点更加接近，同理观察点越近，图像平面上的点间隔越远。</p>
<p>所以当相机是立体纠正时，这些偏移只能在一个方向上移动。他们要么靠近要么远离彼此，要么在同一条线上，要么是对极线。</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgs12b2e4lj21kw0vq0v1.jpg" alt=""></p>
<p>有了基线，可以沿着它们的光学中心排列相机，并减去图像平面上的观察点之间的距离来获得<strong>视差</strong>。一般用像素单位来表示。</p>
<p>但是现在对于编辑并不是很方便，如果将图像缩小，实际是改变了像素大小，然后必须在深度图中缩放每个值。</p>
<h3 id="Removing-Despair-from-Disparity"><a href="#Removing-Despair-from-Disparity" class="headerlink" title="Removing Despair from Disparity"></a>Removing Despair from Disparity</h3><p>苹果选择使用对缩放操作有弹性的归一化值来表示Disparity。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs12rivh1j21kw0vv0w3.jpg" alt=""></p>
<p>这里有两个相似三角形，高亮：</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsk6uz915j21kw0vladn.jpg" alt=""></p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgs13xhh7yj21kw0vfgow.jpg" alt=""></p>
<p>现实世界的三角形边是Z，单位是米，而基线是两个光学中心之间的距离。在防光盒内，同一个三角形表示为像素中的焦距和以像素为单位的Disparity。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs17ml93mj222e15gtco.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgs17ml93mj222e15gtco.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj1gk7i2j21kw0vm41a.jpg" alt=""></p>
<p>数学表示，并化简得到1 / z。当物体移动得更远时，视差会缩小。基线现在绑定在Disparity中了，当处理深度图时，不需要单独携带该信息。</p>
<p>Disparity单位1/米，它可以承受缩放操作，并且从深度到Disparity的转换很简单，只需要 <strong>1除以</strong> 这样一个操作。</p>
<h2 id="Disparity-vs-Depth"><a href="#Disparity-vs-Depth" class="headerlink" title="Disparity vs. Depth"></a>Disparity vs. Depth</h2><ul>
<li>iPhone 7 Plus双摄像头系统是基于Disparity的</li>
<li>Disparity是深度的代理</li>
<li>归一化Disparity是深度的倒数</li>
</ul>
<h1 id="New-Term-Depth-Data"><a href="#New-Term-Depth-Data" class="headerlink" title="New Term: Depth Data"></a>New Term: Depth Data</h1><p>Depth Data是通用术语，对于任何depthy，都可以叫depth data。可以指深度图或者视差图，因为都是深度相关的。</p>
<h2 id="Introducing-AVDepthData"><a href="#Introducing-AVDepthData" class="headerlink" title="Introducing AVDepthData"></a>Introducing AVDepthData</h2><ul>
<li>苹果的平台( iOS, macOS, and tvOS)对于深度的规范表示叫做<code>AVDepthData</code>。</li>
<li>它是AVFoundation框架中的一个类。</li>
<li>它代表深度或差异图。</li>
<li>它还提供了一些方法，可以在深度和差异之间进行转换。</li>
</ul>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">var</span> kCVPixelFormatType_DisparityFloat16: <span class="type">OSType</span> &#123; <span class="keyword">get</span> &#125; <span class="comment">/* 'hdis' */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">var</span> kCVPixelFormatType_DisparityFloat32: <span class="type">OSType</span> &#123; <span class="keyword">get</span> &#125; <span class="comment">/* 'hdis' */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">var</span> kCVPixelFormatType_DepthFloat16: <span class="type">OSType</span> &#123; <span class="keyword">get</span> &#125; <span class="comment">/* 'hdep' */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">var</span> kCVPixelFormatType_DepthFloat32: <span class="type">OSType</span> &#123; <span class="keyword">get</span> &#125; <span class="comment">/* 'fdep' */</span></span><br></pre></td></tr></table></figure>
<p>像RGB图像一样，除了是单通道，但它们仍然可以表示为CV像素缓冲区，现在 <code>CoreVideo</code> 定义了在上一张幻灯片中看到类型的四个新像素格式。因为如果是在GPU上，会要求16位的值，而在CPU上，就都是32位的值。</p>
<p>AVDepthData的核心属性：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@available</span>(iOS <span class="number">11.0</span>, *)</span><br><span class="line">open <span class="class"><span class="keyword">class</span> <span class="title">AVDepthData</span>: <span class="title">NSObject</span> </span>&#123;</span><br><span class="line">    open <span class="keyword">var</span> depthDataType: <span class="type">OSType</span> &#123; <span class="keyword">get</span> &#125;</span><br><span class="line">    open <span class="keyword">var</span> depthDataMap: <span class="type">CVPixelBuffer</span> &#123; <span class="keyword">get</span> &#125;</span><br><span class="line">    open <span class="keyword">var</span> isDepthDataFiltered: <span class="type">Bool</span> &#123; <span class="keyword">get</span> &#125;</span><br><span class="line">    open <span class="keyword">var</span> depthDataAccuracy: <span class="type">AVDepthDataAccuracy</span> &#123; <span class="keyword">get</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Holes"><a href="#Holes" class="headerlink" title="Holes"></a>Holes</h3><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj1ys4duj21kw0vmgno.jpg" alt=""></p>
<p>由于光线，或者边缘难以分清等因素，可能会出现无法得到Disparity的点，这种点叫做holes。深度图也可能被处理来填补这些点。 可以通过基于周围深度数据进行内插，或者通过使用RGB图像中存在的元数据来实现。 <code>AVDepthData</code> 的 <code>isDepthDataFiltered</code> 属性告诉是否以这种方式处理了map。</p>
<h3 id="Calibration-Errors-校准错误"><a href="#Calibration-Errors-校准错误" class="headerlink" title="Calibration Errors 校准错误"></a>Calibration Errors 校准错误</h3><p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj2f0f3nj21kw0viwhm.jpg" alt=""></p>
<p>比如基线计算错误。</p>
<p>iPhone相机不是针孔，iPhone有透镜，并且它的透镜都不是固定的。</p>
<ul>
<li>Optical Image Stabilization </li>
<li>Gravity</li>
<li>Focus Coil</li>
</ul>
<p>如果使用OIS，则透镜可以横向移动来抵消手抖动。重力可以发挥作用，因为它会导致镜头下垂。聚焦致动器实际上是施加电流的弹簧。所以这些原因可能会导致它横向移动一点，而光学中心位置的这些非常小的误差可能导致Disparity的巨大误差。当发生这种情况时，结果是map中每个像素的误差是一个恒定的。 Disparity 值相对于彼此仍然可用，但它们不再反映真实世界的距离。</p>
<h3 id="Depth-Data-Accuracy"><a href="#Depth-Data-Accuracy" class="headerlink" title="Depth Data Accuracy"></a>Depth Data Accuracy</h3><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">extension</span> <span class="title">AVDepthData</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Accuracy</span>: <span class="title">Int</span> </span>&#123;</span><br><span class="line">        <span class="keyword">case</span> relative</span><br><span class="line">        <span class="keyword">case</span> absolute </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因此 <code>AVDepthData</code> 有一个精度的概念。绝对值的精度值意味着单位确实反映了现实世界的距离，没有校准问题。相对精度意味着Z排序仍然保留，但是现实世界的尺度已经丢失。从第三方摄像机获取的深度数据可以报告为绝对或相对，但由于刚刚提到的校准错误，iPhone 7 Plus总是报告相对精度。</p>
<p>相对精度并不是坏的精度。双摄像头的depth完全可以使用。</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsj2uci13j21kw0vlgn9.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj3e7ymsj21kw0c2gmv.jpg" alt=""></p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj3retmxj21kw0dm0tm.jpg" alt=""></p>
<h1 id="Streaming-Depth-Data"><a href="#Streaming-Depth-Data" class="headerlink" title="Streaming Depth Data"></a>Streaming Depth Data</h1><h2 id="AVCamPhotoFilter"><a href="#AVCamPhotoFilter" class="headerlink" title="AVCamPhotoFilter"></a>AVCamPhotoFilter</h2><h2 id="Introducing-AVCaptureDepthDataOutput"><a href="#Introducing-AVCaptureDepthDataOutput" class="headerlink" title="Introducing AVCaptureDepthDataOutput"></a>Introducing AVCaptureDepthDataOutput</h2><p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj45svipj21kw0vb0w9.jpg" alt=""></p>
<p><code>AVFoundation</code> 框架相机捕获类分为三大部分。第一个是 <code>AVCaptureSession</code>，仅仅是个控制对象。你可以告诉它开始或者停止运行，它不做任何事情，除非给它一个输入，比如 <code>AVCaptureDeviceInput</code> ，这里与双摄像头的设备关联，并且给session提供输入。然后需要一个输出，这里是一个新的输出类型 <code>AVCaptureDepthDataOutput</code>，它的功能类似于 <code>VideoDataOutput</code>，除了提供 <code>CoreMedia</code> 示例缓冲区之外，它提供了 <code>AVDepthData</code> 对象。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj4kyda4j21kw0vldl7.jpg" alt=""></p>
<ul>
<li>只有双摄像头才能支持 <code>AVCaptureDepthDataOutput</code>。</li>
<li>将 <code>DepthDataOutput</code> 附加到会话中时，双摄像机自动缩放到2倍，即长焦的全部视野，这是因为为了计算视差，焦距必须相同，而在2倍变焦下，广角摄像机的焦距与长焦相匹配。在计算深度时缩放是被禁用的。</li>
<li>苹果已经向 <code>AVCaptureDevice</code> 添加了一些新的访问器。在双摄像头上，您可以通过查询 <code>supportedDepthDataFormats</code> 属性来发现哪些视频格式支持深度。</li>
<li>还有一个新的 <code>activeDepthDataFormat</code> 属性，可以让您看到 <code>activeDepthDataFormat</code> 是什么或选择一个新的 DepthDataFormat。</li>
</ul>
<h2 id="Supported-Depth-Resolutions-for-Streaming"><a href="#Supported-Depth-Resolutions-for-Streaming" class="headerlink" title="Supported Depth Resolutions for Streaming"></a>Supported Depth Resolutions for Streaming</h2><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj73ubzej21kw0n043r.jpg" alt=""></p>
<p>第一个是受欢迎的照片预设。 在照片预设中，可以从 <code>VideoDataOutput</code> 中获得屏幕尺寸的预览，还可以从photoOutput中获得1200万像素的完整图像。所以在这里 VideoDataOutput提供了1440x1080，这是屏幕尺寸。如果使用DepthDataOutput，可以获得24 fps，最大320x240的depthData。这么小的原因是每秒处理24次视差图已经消耗很多性能了。也可以以较低的分辨率得到它，160x120。</p>
<p>第二个是16x9的格式，这是今年的新格式。去年有一个720p 16x9的格式，帧率高达60 fps。今年这个新格式只有30 fps，但是支持depth。同样支持两种分辨率。</p>
<p>最后，有一个非常小的VGA大小的预设或活动格式，如果只是想要非常小非常快，可以使用它。</p>
<h2 id="Depth-Frame-Rate-Examples"><a href="#Depth-Frame-Rate-Examples" class="headerlink" title="Depth Frame Rate Examples"></a>Depth Frame Rate Examples</h2><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsj7z7mzqj21kw0j2773.jpg" alt=""></p>
<p>AVCaptureDevice允许设置最小和最大视频帧速率，但不允许独立于视频帧速率设置深度帧速率。因为深度需要和视频帧率一致，或者小于视频帧率。例如，如果选择最大视频帧率为24，深度可以跟上这一点，所以得到24 fps的深度。但是，如果选择30 fps视频，则深度跟不上，不过不会选择24，而是15，倍数是比较好的选择。</p>
<p>DepthDataOutput支持过滤深度数据。这样就可以填满空洞，并且随着你的移动也可以比较平滑，这样就不会看到从帧到帧的时间跳跃。</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open <span class="keyword">var</span> isFilteringEnabled: <span class="type">Bool</span></span><br></pre></td></tr></table></figure>
<h2 id="非同步数据输出"><a href="#非同步数据输出" class="headerlink" title="非同步数据输出"></a>非同步数据输出</h2><p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsj8emigvj21kw0ul444.jpg" alt=""></p>
<p>现在有四种数据输出：</p>
<p>第一个是 <code>VideoDataOutput</code> ，从iOS 4开始，它是以30 fps或60 fps的流媒体方式一次给出视频帧。 还有一个 <code>AudioDataOutput</code>，通常会以44.1的速度一次推送1024个PCM帧。 还有一个 <code>MetadataOutput</code> 可以提供面部，检测到的面孔或条形码，并且这些都偶尔出现。 他们可能会有一些延迟，寻找面孔多达四帧延迟。</p>
<p>第四个就是 <code>DepthDataOutput</code> ，是以视频的帧速率或以视频均匀分割的速率传送。</p>
<p>如果关心同时处理所有这些数据，或者处理一定的演示时间。为了处理所有这些数据输出，您必须拥有一个非常复杂的缓冲机制，以便跟踪所有进入的时间，</p>
<h2 id="Synchronized-Data-Output"><a href="#Synchronized-Data-Output" class="headerlink" title="Synchronized Data Output"></a>Synchronized Data Output</h2><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsj8s3gxgj21kw0vjdm7.jpg" alt=""></p>
<p>在iOS 11中，苹果添加了一个名为 <code>AVCaptureDataOutputSynchronizer</code> 的新同步对象。它可以在单个统一回调中为给定呈现时间，提供所有可用数据，并传递一个称为<code>AVCaptureSynchronizedDataCollection</code> 的集合对象。</p>
<p>所以这样就可以指定一个主输出，一个最重要的输出，一个希望所有其他东西要同步的输出，然后只要它需要，就可以做这个工作， 以确保给定演示时间的所有数据在可用之前提供给单独的统一回调。它将为你提供输出的所有数据，或者如果确保没有特定输出的数据，它将继续提供与它有关的集合。</p>
<p>下面一个代码示例：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">dataOutputSynchronizer</span><span class="params">(<span class="number">_</span> synchronizer: AVCaptureDataOutputSynchronizer, didOutput synchronizedDataCollection: AVCaptureSynchronizedDataCollection)</span></span> &#123;</span><br><span class="line">    <span class="comment">// Iterate through an AVCaptureSynchronizedDataCollection using fast enumeration</span></span><br><span class="line">    <span class="keyword">for</span> syncedData <span class="keyword">in</span> synchronizedDataCollection &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> syncedDepthData = syncedData <span class="keyword">as</span>? <span class="type">AVCaptureSynchronizedDepthData</span> &#123;</span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以像数组一样使用它，也可以像字典那样使用它，具体取决于要做什么。</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">dataOutputSynchronizer</span><span class="params">(<span class="number">_</span> synchronizer: AVCaptureDataOutputSynchronizer, didOutput synchronizedDataCollection: AVCaptureSynchronizedDataCollection)</span></span> &#123;</span><br><span class="line">    <span class="comment">// Use dictionary-esque subscripting to find a particular data</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> synDepth = synchronizedDataCollection[<span class="keyword">self</span>.ddo] <span class="keyword">as</span>? <span class="type">AVCaptureSynchronizedDepthData</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Streaming-Camera-Intrinsics"><a href="#Streaming-Camera-Intrinsics" class="headerlink" title="Streaming Camera Intrinsics"></a>Streaming Camera Intrinsics</h2><p>iOS 11中还有一个新的流式传输功能，当使用 <code>VideoDataOutput</code> 时，支持每个视频帧的相机内在功能。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj96x8qej21kw0qnado.jpg" alt=""></p>
<p>上面讲到针孔相机，为了将3D空间中的点转换为2D空间，需要两个信息，光学中心和焦距。在计算机视觉中，可以使用这些属性通过使用逆变换将2D图像重新投影回3D空间，这在新的AR kit中是重点。</p>
<p>iOS 11中的新功能，可以选择在每个视频帧中收到这样一组内在函数，通过调用 <code>AVCaptureConnection</code> 的 <code>isCameraIntrinsicMatrixDeliveryEnabled</code> 来选择。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsj9m3a0pj21kw0r2got.jpg" alt=""></p>
<p>相机内在函数是描述相机几何属性的3x3矩阵。fx和fy是像素焦距。它们是分开的x值和y值，因为有时相机具有变形镜头或变形像素。</p>
<p>在iOS设备上，我们的相机总是具有一致的像素，所以fx和fy总是相同的值。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsj9zc3glj21kw0q2tbq.jpg" alt=""></p>
<p>x0和y0是透镜光学中心的像素坐标。</p>
<p>这些都是像素值，它们是以提供它们的视频缓冲区的分辨率给出的。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjacfo37j21kw0s4wi7.jpg" alt=""></p>
<p>所以，一旦你选择了，可以期望以流式方式获取样本缓冲区，可以获得这个附件，有效载荷是一个C/F数据，它包装一个矩阵3x3浮点数，这是一个SIMD数据类型。</p>
<h1 id="Capturing-Photos-with-Depth"><a href="#Capturing-Photos-with-Depth" class="headerlink" title="Capturing Photos with Depth"></a>Capturing Photos with Depth</h1><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjaphyivj21fm0m2n65.jpg" alt=""></p>
<p>AVCam是显示如何使用 <code>AVFoundation</code> 拍摄照片和电影的示范代码。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjb6bur5j209s0c2n1n.jpg" alt=""></p>
<p>注意，虽然已经添加了深入支持，但是你看不到任何depth相关的东西。因为当能够拍摄这些铅笔时，实际上并没有看到深度的表现，而是存储在照片中。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjbjoem0j20yi1pckb1.jpg" alt=""></p>
<p>照相结束后，打开相册后编辑，上面有了景深的按钮，可以对景深做效果处理。在iOS 11中，以人像模式拍摄的所有照片现在都会在照片中存储深度信息，因此它们会为您的新创意应用程序添加素材。</p>
<h2 id="Photos-with-Depth"><a href="#Photos-with-Depth" class="headerlink" title="Photos with Depth"></a>Photos with Depth</h2><p>当拍摄深度照片时，支持很多的捕获选项。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjby5psej21e20ec0u5.jpg" alt=""></p>
<p>可以使用深度进行闪光拍摄，可以静态图像稳定带深度信息。 甚至可以自动曝光括号，例如加2，减2 EV。 可以使Live Photos带有深度信息。</p>
<h2 id="Capturing-Photos-with-Depth-1"><a href="#Capturing-Photos-with-Depth-1" class="headerlink" title="Capturing Photos with Depth"></a>Capturing Photos with Depth</h2><p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjcbgjusj21kw0t4q6u.jpg" alt=""></p>
<p><code>AVCapturePhotoOutput</code>，这是去年推出的一个类，它是 <code>AVCaptureStillImageOutput</code> 的继承者。它处理复杂的照片请求非常出色。</p>
<p>编程模型是填写一个称为 <code>AVCapturePhotoSettings</code> 的请求，通过传递请求和稍后再调用的代理来启动照片捕获。而且photoOutput是捕获实时照片，裸RAW图像和Apple P3宽色图像的唯一界面。此外，在iOS 11中，它是捕获HEIF文件格式的唯一方法。<code>AVCapturePhotoOutput</code> 需要进行许多更改以支持HEIF，因此在iOS 11中，为了适应这些许多变化，添加了新的委托回调。</p>
<p>一个简单示例：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">photoOutput</span><span class="params">(<span class="number">_</span> output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto</span><br><span class="line">, error: Error?)</span></span></span><br></pre></td></tr></table></figure>
<p>这是替代将获得示例缓冲区的回调。现在得到一个名为 <code>AVCapturePhoto</code> 的新对象。<code>AVCapturePhoto</code> 是深度唯一的传递媒介，所以如果想要深度，需要通过实现这个新的代理回调来操作。</p>
<h2 id="Requesting-Depth-with-Photos"><a href="#Requesting-Depth-with-Photos" class="headerlink" title="Requesting Depth with Photos"></a>Requesting Depth with Photos</h2><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjcpmo86j21kw0qwtfa.jpg" alt=""></p>
<p>此外，在开始会话之前需要明确地选择 <code>DepthDataDelivery</code>。它需要放大到2倍，使焦距匹配，并且需要锁定自己，禁止缩放。</p>
<p>开始运行会话之前，告诉photoOutput我想要 <code>DepthDataDeliveryEnabled(photoOutput.isDepthDataDeliveryEnabled)</code>，然后在每个照片请求的基础上，这里是当你实际拍摄照片，你会填写一个设置对象，并且再一次我想在这张照片中深度(<code>photoSettings.isDepthDataDeliveryEnabled</code>)。</p>
<p>然后，可以使用产生的<code>AVCapturePhoto</code>，它具有一个名为 <code>AVDepthData</code> 的访问器。</p>
<h2 id="High-Res-Photo-Depth-Maps"><a href="#High-Res-Photo-Depth-Maps" class="headerlink" title="High Res Photo Depth Maps"></a>High Res Photo Depth Maps</h2><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjd6bbfmj21kw0men2h.jpg" alt=""></p>
<p>在iOS上，大多数AVCaptureDevice格式都具有比流式分辨率更高的静态图像分辨率。depth也是同理。</p>
<p>如果是流式深度，用实时的方式来满足24 fps，有很多工作需要做，但是如果是照片，有一点额外的时间，因为它不需要实时发送，所以可以达到非常高品质的map，超过流分辨率的两倍。</p>
<p>长宽比与视频的长宽比一致。</p>
<h2 id="Rectilinear-vs-Lens-Distorted-Images"><a href="#Rectilinear-vs-Lens-Distorted-Images" class="headerlink" title="Rectilinear vs. Lens Distorted Images"></a>Rectilinear vs. Lens Distorted Images</h2><p>捕获和嵌入照片的深度图都是畸变的。</p>
<p>之前展示的所有相机图是针孔相机。 针孔相机没有镜头，因此图像是直线的; 也就是说，光以直线穿过小孔，并在图像平面上呈现几何完美的复制倒置物体。</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjdkh5f8j21jw0x2409.jpg" alt=""></p>
<p>如果有一个这样的完美的正方形网格，并用针孔相机拍摄它，它将在图像平面上看起来像这样，但是颠倒的。直线会保持直线。</p>
<p>但是在现实世界中，需要让更多的光线进入，所以需要镜头，镜头有径向变形。这些失真也存在于捕获的图像中，因为它们以稍微奇怪的方式弯曲成图像传感器。</p>
<p>在极端情况下，通过不良镜头捕获的直线可能看起来像这样：</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjdy15ayj21ei0wugs8.jpg" alt=""></p>
<p>在比较广角和长焦图像之前，必须做一个额外的步骤：</p>
<p>必须使那些扭曲的图像直线化; 也就是说，使用校准的系数集合来解决它们，并且这些系数表征了镜头的失真。</p>
<h2 id="Depth-Map-Distortions"><a href="#Depth-Map-Distortions" class="headerlink" title="Depth Map Distortions"></a>Depth Map Distortions</h2><p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjebq38zj21kw0y17a0.jpg" alt=""></p>
<p>现在可以确定地比较两个图像中的点，并找到一个完美的，真实的，直线的视差图，看起来像这样：</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjeoutp6j21kw0rl79d.jpg" alt=""></p>
<p>差距图匹配物理世界，但它与刚刚拍摄的图像不符，因为镜头有扭曲，所以现在必须做另一个步骤，就是将视差图重新映射回图像，使用一组逆透镜系数来做到这一点，最后的视差图具有与其伴随图像相同的几何失真。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjf34n5zj21kw0hfact.jpg" alt=""></p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjifd9fyj21kw0dhjv1.jpg" alt=""></p>
<p>这意味着开箱即用的depthDataMaps附带的照片适用于过滤器，适用于效果。不完美的是重建3D场景。 如果想这样做，应该使它们是直线的：</p>
<h2 id="Depth-in-Image-Files"><a href="#Depth-in-Image-Files" class="headerlink" title="Depth in Image Files"></a>Depth in Image Files</h2><p>简单地介绍图像文件中的深度数据的物理结构。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjita42uj21kw0kgjv6.jpg" alt=""></p>
<p>iOS 11苹果有两种图像支持深度。第一个是HEIF HEVC，新格式，也称为HEIC文件，对深度的支持是最好的。文件内有一个称为辅助图像的区域，可以存储视差或深度或透明度map，这就是存储的地方。</p>
<p>我们将其编码为单色HEVC，还存储对于深度工作非常重要的元数据，例如有关滤光器的信息，精度，相机校准信息（如镜头失真）以及一些渲染指令。所有这些都与辅助图像一起编码为XMP。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjj6uqnyj21kw0j9adw.jpg" alt=""></p>
<p>第二个就是JPEG，虽然这并不是很好的方法，但还是支持了。map是8位有损JPEG，如果它被过滤，或者如果它没有一个数字，使用16位无损JPEG编码来保存所有非数字，苹果将它作为第二个图像存储在JPEG的底部，如果你熟悉的话，它就像一个多画面对象。同样编码是XMP。</p>
<h1 id="Dual-Photo-Capture"><a href="#Dual-Photo-Capture" class="headerlink" title="Dual Photo Capture"></a>Dual Photo Capture</h1><p>对于双摄像机最需要的开发者功能，双重照片捕获。</p>
<p>到目前为止，当使用双相机拍照时，仍然只能获得一张图像。 它是来自广角还是来自长焦，取决于缩放的位置，或者如果在1和2X之间的区域，可能会获得两者的一部分，因为苹果进行了一些混合，使得到更好的图片，但仍然只有一个。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjjnx0fej21h00nm4jf.jpg" alt=""></p>
<p>现在，苹果两张图片都给了：通过单一请求，可以获得广角和长焦的全部1200万像素的照片。</p>
<h2 id="Requesting-Dual-Photo-Delivery"><a href="#Requesting-Dual-Photo-Delivery" class="headerlink" title="Requesting Dual Photo Delivery"></a>Requesting Dual Photo Delivery</h2><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjk05091j21kw0h643o.jpg" alt=""></p>
<p>与上述的深度操作非常相似。设置两个属性 <code>photoOutput.isDualCameraDualPhotoDeliveryEnabled</code> , <code>photoSettings.isDualCameraDualPhotoDeliveryEnabled</code> 为<code>ture</code>。照片的回调就会给两份。</p>
<p>假设你要求RAW 和 HEIF双照。 那么会得到4份，因为将得到两个广角和两个长焦的RAW和HEIF。</p>
<h2 id="Dual-Photo-Capture-1"><a href="#Dual-Photo-Capture-1" class="headerlink" title="Dual Photo Capture"></a>Dual Photo Capture</h2><p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjkecu5zj21kw0eu0v8.jpg" alt=""></p>
<p>现在，我们支持与深度相关的所有功能，可以使用双摄照片，自动SIS，曝光等级，可以根据需要选择深度。</p>
<h2 id="Dual-Photo-Capture-Zoom"><a href="#Dual-Photo-Capture-Zoom" class="headerlink" title="Dual Photo Capture + Zoom"></a>Dual Photo Capture + Zoom</h2><p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fgsjkscp53j21kw0nhq95.jpg" alt=""></p>
<p>假设你的应用程序只显示长焦的视野。 那么广角摄像机有更多的信息，所以如果你拍照，实际上给人的可见区域以外的东西，这可能是一个隐私的关注。所以如果是缩放，苹果提供双重照片，但外部变黑，使它们与预览中看到的视野相匹配。</p>
<p>如果您想要完整的图像，可以不要设置缩放。</p>
<p>怎么知道外面是否有黑色区域？在图像内部，存储一个纯净的孔径矩形，它定义了有效像素的区域。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjl4do87j21kw0b5mzb.jpg" alt=""></p>
<p>也可以使用相机校准数据传送双重照片。相机校准数据是进行增强现实，虚拟现实，镜头失真校正等需要的数据。 因此，无论是广角的还是长焦和相机校准数据，都可以制作自己的深度图。</p>
<h2 id="Introducing-AVCameraCalibrationData"><a href="#Introducing-AVCameraCalibrationData" class="headerlink" title="Introducing AVCameraCalibrationData"></a>Introducing AVCameraCalibrationData</h2><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjlgvpy2j21ic0cyac0.jpg" alt=""></p>
<p>相机校准的属性。<code>AVCameraCalibrationData</code> 是相机校准的model类。如果要求深度，可以得到一个 <code>AVDepthData</code>。 这就是 <code>AVDepthData</code> 的属性。 如果从AVCapturePhoto中选择了此功能，也可以获得该功能。 所以选择加入这个照片来说，我想用相机进行相机校准，这个照片效果很好。</p>
<p>如果正在进行双重照片拍摄，需要双面照片，并要求相机校准，将获得两张照片回调，并且可以获得具有广角效果的广角校准，和具有长焦效果的长焦校准。</p>
<h3 id="intrinsicMatrix"><a href="#intrinsicMatrix" class="headerlink" title="intrinsicMatrix"></a>intrinsicMatrix</h3><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjltcn79j21kw0midix.jpg" alt=""></p>
<p>和之前的streaming VideoDataOutput情况很相似。但是仅仅是这样深度数据的分辨率可能非常低，所以苹果又提供了一套单独的维度。通常，它们是传感器的完整尺寸，因此，您以获得很多精度，在 <code>intrinsicMatrix</code> 中有很高的分辨率。</p>
<h3 id="extrinsicMatrix"><a href="#extrinsicMatrix" class="headerlink" title="extrinsicMatrix"></a>extrinsicMatrix</h3><p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjm6qrydj21kw0olmzw.jpg" alt=""></p>
<p><code>extrinsicMatrix</code>：这是描述相机在真实世界中姿势的属性。当使用从立体矫正摄像机得到的图像进行三角测量时，需要将其与另一个相比较。而外在特征被表现为一个单一的矩阵，但是两种矩阵被挤压在一起。</p>
<p>左边是旋转矩阵。这是一个3x3，它描述了相机相对于真实世界如何旋转。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjmjskgjj21kw0nv41b.jpg" alt=""></p>
<p>还有一个1x3矩阵，描述了相机的翻转，或与世界边缘的距离。注意，当使用双摄像头时，长焦摄像机是世界的边缘，这使得它非常容易。</p>
<p>如果只是得到一个长焦图像，你得到的矩阵将是一个单位矩阵。 如果正在使用广角和长焦，广角将不是单位矩阵，因为它描述了与长焦镜头的姿态和距离。 但是，使用extrinsics，可以计算广角与长焦之间的基线。</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fgsjmyjqafj21kw0o4q7g.jpg" alt=""></p>
<p>这里有两个属性需要注意。一个是 <code>lensDistortionCenter</code>。这描述了传感器上与镜头失真中心重合的点。这通常与镜头的光学中心不同。</p>
<p>就像上图的扭曲，透镜上的径向扭曲像树环一样，这将是树环的中心。 </p>
<p>同时还有一个属性是<code>lensDistortionLookupTable</code>，可以将其视为将 <code>lensDistortionCenter</code> 连接到最长半径的多个浮点数。<code>lensDistortionLookupTable</code> 是包含在数据中的C浮点数组。如果沿着这些虚线的每个点都是0，那么就拥有了世界上唯一一个完美的镜头，因为这就根本没有径向畸变了。</p>
<p>如果是正值，则表示半径有延长。如果是负值，则表示有压缩。</p>
<p>将整个表格整合在一起，就可以了解镜头的颠簸情况。</p>
<p>要对图像应用失真校正，需要以一个空目标缓冲区开始，然后逐行迭代，并且对于每个点，都使用 <code>lensDistortionLookupTable</code> 在失真的图像中找到相应的值，然后将该值写入到输出缓冲区中的正确位置。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fgsjnb85n2j21kw0oin1a.jpg" alt=""></p>
<p>这个是比较难实现的代码，苹果在 <code>AVCameraCalibrationData.h</code> 中提供了一个参考实现。实际是把代码放到了头文件里面。全都有注释。是个很大的objective C函数。它描述了如何纠正图像或如何反扭曲图像，具体取决于传给它的表格。还有一个表格的逆，它描述了如何从扭曲回到非扭曲。</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fgsjnqsllkj21kw0s87c6.jpg" alt=""></p>
<ul>
<li>iPhone 7 Plus双摄像头不是飞行时间相机系统，是Disparity系统。</li>
<li>此外，苹果平台上对深度的规范表示是 <code>AVDepthData</code>。</li>
<li>了解了intrinsics、extrinsics、lens distortion的信息。都是 <code>AVCameraCalibrationData</code> 的属性。</li>
<li>了解了<code>AVCaptureDepthDataOutput</code>，它提供了可以过滤的流式深度。</li>
<li>可以使用 <code>AVCapturePhotoOutput</code> 捕获带有深度信息的照片。</li>
<li>最后讲到了双摄像头，双照片，对于某些计算机视觉可以单独用到广角和长焦的照片。</li>
</ul>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/iOS/">iOS</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/深度/">深度</a><a href="/tags/iOS/">iOS</a><a href="/tags/双摄/">双摄</a><a href="/tags/图像/">图像</a><a href="/tags/WWDC/">WWDC</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://yoferzhang.com/post/20170621wwdc2017session508/" data-title="【iOS】iPhone摄影中的深度捕捉(WWDC2017-Session 507) | YoferZhang 的博客" data-tsina="2848249334" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/post/20170810SwiftSyntaxTour/" title="【iOS】Swift语法畅游，语法查询">
  <strong>上一篇：</strong><br/>
  <span>
  【iOS】Swift语法畅游，语法查询</span>
</a>
</div>


<div class="next">
<a href="/post/20170409ML06LogisticRegression/"  title="【AI】机器学习入门系列06，Logistic Regression逻辑回归">
 <strong>下一篇：</strong><br/> 
 <span>【AI】机器学习入门系列06，Logistic Regression逻辑回归
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>



</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Depth-and-disparity-on-iPhone-7-Plus"><span class="toc-number">2.</span> <span class="toc-text">Depth and disparity on iPhone 7 Plus</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Dual-Camera-Zoom-双摄变焦"><span class="toc-number">2.1.</span> <span class="toc-text">Dual Camera Zoom 双摄变焦</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Portrait-Mode"><span class="toc-number">2.2.</span> <span class="toc-text">Portrait Mode</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Deep-Learning"><span class="toc-number">3.</span> <span class="toc-text">Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Map"><span class="toc-number">3.1.</span> <span class="toc-text">Depth Map</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Disparity"><span class="toc-number">3.2.</span> <span class="toc-text">Disparity</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#baseline基线"><span class="toc-number">3.2.1.</span> <span class="toc-text">baseline基线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Z"><span class="toc-number">3.2.2.</span> <span class="toc-text">Z</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Removing-Despair-from-Disparity"><span class="toc-number">3.2.3.</span> <span class="toc-text">Removing Despair from Disparity</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Disparity-vs-Depth"><span class="toc-number">3.3.</span> <span class="toc-text">Disparity vs. Depth</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#New-Term-Depth-Data"><span class="toc-number">4.</span> <span class="toc-text">New Term: Depth Data</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introducing-AVDepthData"><span class="toc-number">4.1.</span> <span class="toc-text">Introducing AVDepthData</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Holes"><span class="toc-number">4.1.1.</span> <span class="toc-text">Holes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Calibration-Errors-校准错误"><span class="toc-number">4.1.2.</span> <span class="toc-text">Calibration Errors 校准错误</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Depth-Data-Accuracy"><span class="toc-number">4.1.3.</span> <span class="toc-text">Depth Data Accuracy</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Streaming-Depth-Data"><span class="toc-number">5.</span> <span class="toc-text">Streaming Depth Data</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AVCamPhotoFilter"><span class="toc-number">5.1.</span> <span class="toc-text">AVCamPhotoFilter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introducing-AVCaptureDepthDataOutput"><span class="toc-number">5.2.</span> <span class="toc-text">Introducing AVCaptureDepthDataOutput</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Supported-Depth-Resolutions-for-Streaming"><span class="toc-number">5.3.</span> <span class="toc-text">Supported Depth Resolutions for Streaming</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Frame-Rate-Examples"><span class="toc-number">5.4.</span> <span class="toc-text">Depth Frame Rate Examples</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非同步数据输出"><span class="toc-number">5.5.</span> <span class="toc-text">非同步数据输出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Synchronized-Data-Output"><span class="toc-number">5.6.</span> <span class="toc-text">Synchronized Data Output</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Streaming-Camera-Intrinsics"><span class="toc-number">5.7.</span> <span class="toc-text">Streaming Camera Intrinsics</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Capturing-Photos-with-Depth"><span class="toc-number">6.</span> <span class="toc-text">Capturing Photos with Depth</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Photos-with-Depth"><span class="toc-number">6.1.</span> <span class="toc-text">Photos with Depth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Capturing-Photos-with-Depth-1"><span class="toc-number">6.2.</span> <span class="toc-text">Capturing Photos with Depth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requesting-Depth-with-Photos"><span class="toc-number">6.3.</span> <span class="toc-text">Requesting Depth with Photos</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#High-Res-Photo-Depth-Maps"><span class="toc-number">6.4.</span> <span class="toc-text">High Res Photo Depth Maps</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rectilinear-vs-Lens-Distorted-Images"><span class="toc-number">6.5.</span> <span class="toc-text">Rectilinear vs. Lens Distorted Images</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Map-Distortions"><span class="toc-number">6.6.</span> <span class="toc-text">Depth Map Distortions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-in-Image-Files"><span class="toc-number">6.7.</span> <span class="toc-text">Depth in Image Files</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dual-Photo-Capture"><span class="toc-number">7.</span> <span class="toc-text">Dual Photo Capture</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Requesting-Dual-Photo-Delivery"><span class="toc-number">7.1.</span> <span class="toc-text">Requesting Dual Photo Delivery</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dual-Photo-Capture-1"><span class="toc-number">7.2.</span> <span class="toc-text">Dual Photo Capture</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dual-Photo-Capture-Zoom"><span class="toc-number">7.3.</span> <span class="toc-text">Dual Photo Capture + Zoom</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introducing-AVCameraCalibrationData"><span class="toc-number">7.4.</span> <span class="toc-text">Introducing AVCameraCalibrationData</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#intrinsicMatrix"><span class="toc-number">7.4.1.</span> <span class="toc-text">intrinsicMatrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#extrinsicMatrix"><span class="toc-number">7.4.2.</span> <span class="toc-text">extrinsicMatrix</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Summary"><span class="toc-number">8.</span> <span class="toc-text">Summary</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="github-card">
<p class="asidetitle">Github 名片</p>
<div class="github-card" data-github="yoferzhang" data-theme="medium"></div>
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>



  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/AI/" title="AI">AI<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/C语言/" title="C语言">C语言<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/iOS/" title="iOS">iOS<sup>52</sup></a></li>
		  
		
		  
			<li><a href="/categories/渔/" title="渔">渔<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/艺术/" title="艺术">艺术<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/读书感悟/" title="读书感悟">读书感悟<sup>17</sup></a></li>
		  
		
		  
			<li><a href="/categories/随笔/" title="随笔">随笔<sup>3</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/欧美/" title="欧美">欧美<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/深度学习/" title="深度学习">深度学习<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/小说/" title="小说">小说<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/分类/" title="分类">分类<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/东京/" title="东京">东京<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/旅游/" title="旅游">旅游<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/文学/" title="文学">文学<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/悬疑/" title="悬疑">悬疑<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/AlphaGo/" title="AlphaGo">AlphaGo<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/C语言/" title="C语言">C语言<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/莎士比亚/" title="莎士比亚">莎士比亚<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/线性回归/" title="线性回归">线性回归<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/AR/" title="AR">AR<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/日本/" title="日本">日本<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/笔记/" title="笔记">笔记<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/神经网络/" title="神经网络">神经网络<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/tableview/" title="tableview">tableview<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/音乐/" title="音乐">音乐<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/摄影/" title="摄影">摄影<sup>2</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://hexo.io/" target="_blank" title="Hexo">Hexo</a>
            
          </li>
        
          <li>
            
            	<a href="https://github.com/yoferzhang" target="_blank" title="Github">Github</a>
            
          </li>
        
          <li>
            
            	<a href="http://ww3.sinaimg.cn/large/a9c4d5f6jw1f2cbilh1uyj2076076t97.jpg" target="_blank" title="WeChat">WeChat</a>
            
          </li>
        
          <li>
            
            	<a href="https://cn.linkedin.com/in/耀琦-张-771388117" target="_blank" title="LinkedIn">LinkedIn</a>
            
          </li>
        
    </ul>
</div>

  

<div class="doubanshow">
<p class="asidetitle">豆瓣秀</p>
<div>
<script type="text/javascript" src="http://www.douban.com/service/badge/zyq522376829/?show=collection&amp;n=12&amp;columns=3&amp;hidelogo=yes&amp;hideself=yes&amp;cat=book|movie" ></script>
</div>
</div>


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=2848249334&verifier=b3593ceb&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Yofer Zhang in Tencent. <br/>
			This is my blog,thank you to here.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2848249334" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/yoferzhang" target="_blank" class="icon-github" title="github"></a>
		
		
		<a href="http://stackoverflow.com/users/yofer-zhang" target="_blank" class="icon-stack-overflow" title="stackoverflow"></a>
		
		
		<a href="https://twitter.com/LuciferZhangyq" target="_blank" class="icon-twitter" title="twitter"></a>
		
		
		<a href="https://www.facebook.com/luciferzhang" target="_blank" class="icon-facebook" title="facebook"></a>
		
		
		<a href="https://www.linkedin.com/in/耀琦-张-771388117?trk=hp-identity-name" target="_blank" class="icon-linkedin" title="linkedin"></a>
		
		
		<a href="https://www.douban.com/people/zyq522376829" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		<a href="http://www.zhihu.com/people/yoferzhang" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		<a href="https://plus.google.com/110295955443575724222?rel=author" target="_blank" class="icon-google_plus" title="Google+"></a>
		
		
		<a href="mailto:yoferzhang@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2018 
		
		<a href="/about" target="_blank" title="Yofer Zhang">Yofer Zhang</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          c.click();
        }
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>




<script type="text/javascript">

var disqus_shortname = 'yoferzhang';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>








<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-83435219-1', 'yoferzhang.com');  
ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?a6dda28cb6f26de955e11a3716d6ce9b";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End --><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  </body>
</html>
